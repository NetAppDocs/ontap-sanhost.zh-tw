---
sidebar: sidebar 
permalink: nvme_rhel_87.html 
keywords: nvme, linux, rhel, red hat, enterprise 
summary: 如何針對RHEL 8.7設定NVMe主機、ONTAP 並搭配使用功能 
---
= 適用於 ONTAP RHEL 8.7 的 NVMe 主機組態
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Red Hat Enterprise Linux （ RHEL ） 8.7 搭配 ANA （非對稱命名空間存取）支援 NVMe over Fabrics 或 NVMe （包括 NVMe / FC 及其他傳輸）。ANA是NVMe環境中的非對稱邏輯單元存取（ALUA）、目前是以核心內建NVMe多重路徑來實作。在此程序中、您可以使用 RHEL 8.7 上的 ANA 、 ONTAP 作為目標、來啟用內核 NVMe 多重路徑的 NVMe 。

如需支援組態的詳細資訊，請參閱link:https://mysupport.netapp.com/matrix/["互通性對照表工具"^]。



== 功能

RHEL 8.7除了支援NVMe / FC、還支援NVMe / TCP（技術預覽功能）。原生NVMe CLI套件中的NetApp外掛程式能夠顯示ONTAP NVMe / FC和NVMe / TCP命名空間的詳細資訊。



== 已知限制

* 在RHEL 8.7中、內核NVMe多重路徑預設為停用。因此、您需要手動啟用。
* RHEL 8.7上的NVMe/TCP仍是技術預覽功能、因為仍有未解決的問題。請參閱 link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/8.7_release_notes/index["RHEL 8.7版本說明"^] 以取得詳細資料。
* 目前不支援使用 NVMe 型傳輸協定進行 SAN 開機。




== 啟用內核NVMe多重路徑

您可以使用下列程序來啟用核心內建 NVMe 多重路徑。

.步驟
. 在伺服器上安裝RHEL 8.7。
. 安裝完成後、請確認您正在執行指定的 RHEL 8.7 核心。如需支援版本的最新清單，請參閱link:https://mysupport.netapp.com/matrix/["互通性對照表工具"^]。
+
範例：

+
[listing]
----
# uname -r
4.18.0-425.3.1.el8.x86_64
----
. 安裝「NVMe-CLI（NVMe - CLI）套件：
+
範例：

+
[listing]
----
# rpm -qa|grep nvme-cli
nvme-cli-1.16-5.el8.x86_64
----
. 啟用核心內建NVMe多重路徑：
+
* 範例 *

+
[listing]
----
# grubby --args=nvme_core.multipath=Y --update-kernel
/boot/vmlinuz-4.18.0-425.3.1.el8.x86_64
----
. 在主機上、檢查位於「/etc/nape/hostnqn」的主機NQN字串、並驗證其是否符合ONTAP 位於「the」（子系統）上之對應子系統的主機NQN字串。範例：
+
[listing]
----

# cat /etc/nvme/hostnqn

          nqn.2014-08.org.nvmexpress:uuid:a7f7a1d4-311a-11e8-b634-            7ed30aef10b7

::> vserver nvme subsystem host show -vserver vs_nvme167
Vserver     Subsystem       Host NQN
----------- --------------- ----------------
vs_nvme167 rhel_167_LPe35002  nqn.2014-08.org.nvmexpress:uuid: a7f7a1d4-311a-11e8-b634-7ed30aef10b7

----
+

NOTE: 如果主機NQN字串不相符、您應該使用「vserver modify」命令來更新對應ONTAP 的NVMe子系統上的主機NQN字串、以符合主機上的主機NQN字串「/etc/nvm/hostnqn」。

. 重新啟動主機。
+
[NOTE]
====
如果您打算在同一部主機上同時執行 NVMe 和 SCSI 共存的流量、 NetApp 建議分別針對 ONTAP 命名空間使用核心內建 NVMe 多重路徑、以及針對 ONTAP LUN 使用 dm-multipath 。這表示ONTAP 應從dm-multipaths中排除支援的對象名稱空間、以避免dm-multipaths宣告這些命名空間裝置。您可以將啟用外部設定新增至來執行此作業 `/etc/multipath.conf` 檔案：

[listing]
----
# cat /etc/multipath.conf
defaults {
        enable_foreign     NONE
}
----
執行「stystemctl restart multipathd」命令重新啟動多路徑精靈、以允許新的設定生效。

====




== 設定NVMe/FC

您可以為 Broadcom / Emulex 或 Marvell/Qlogic 介面卡設定 NVMe / FC 。

[role="tabbed-block"]
====
.Broadcom / Emulex
--
.步驟
. 確認您使用的是支援的介面卡。如需支援介面卡的目前清單，請參閱link:https://mysupport.netapp.com/matrix/["互通性對照表工具"^]。
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
LPe35002-M2
LPe35002-M2
# cat /sys/class/scsi_host/host*/modeldesc
Emulex LightPulse LPe35002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe35002-M2 2-Port 32Gb Fibre Channel Adapter
----
. 請確認您使用的是建議的Broadcom lfit韌體和收件匣驅動程式。如需支援的介面卡驅動程式和韌體版本的最新清單，請參閱link:https://mysupport.netapp.com/matrix/["互通性對照表工具"^]。
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
14.0.505.12, sli-4:6:d
14.0.505.12, sli-4:6:d
# cat /sys/module/lpfc/version
0:14.0.0.15
----
. 確認「lffc_enable _FC4_type]已設定為3
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. 驗證啟動器連接埠是否已啟動並正在執行、以及您是否可以看到目標LIF。
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x100000109b95467c
0x100000109b95467b
# cat /sys/class/fc_host/host*/port_state
Online
Online
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b95467c WWNN x200000109b95467c DID x0a1500 ONLINE
NVME RPORT       WWPN x2071d039ea36a105 WWNN x206ed039ea36a105 DID x0a0907 TARGET DISCSRVC ONLINE
NVME RPORT       WWPN x2072d039ea36a105 WWNN x206ed039ea36a105 DID x0a0805 TARGET DISCSRVC ONLINE

NVME Statistics
LS: Xmt 00000001c7 Cmpl 00000001c7 Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 0000000004909837 Issue 0000000004908cfc OutIO fffffffffffff4c5
abort 0000004a noxri 00000000 nondlp 00000458 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000061 Err 00017f43

NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b95467b WWNN x200000109b95467b DID x0a1100 ONLINE
NVME RPORT       WWPN x2070d039ea36a105 WWNN x206ed039ea36a105 DID x0a1007 TARGET DISCSRVC ONLINE
NVME RPORT       WWPN x206fd039ea36a105 WWNN x206ed039ea36a105 DID x0a0c05 TARGET DISCSRVC ONLINE

NVME Statistics
LS: Xmt 00000001c7 Cmpl 00000001c7 Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 0000000004909464 Issue 0000000004908531 OutIO fffffffffffff0cd
abort 0000004f noxri 00000000 nondlp 00000361 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 0000006b Err 00017f99
----


--
.適用於 NVMe / FC 的 Marvell/QLogic FC 介面卡
--
RHEL 8.7 核心內建的原生收件匣 `qla2xxx`驅動程式具有最新的修正程式。這些修正對於 ONTAP 支援至關重要。

.步驟
. 使用下列命令、確認您執行的是支援的介面卡驅動程式和韌體版本：
+
[listing]
----
# cat /sys/class/fc_host/host*/symbolic_name
QLE2772 FW:v9.08.02 DVR:v10.02.07.400-k-debug
QLE2772 FW:v9.08.02 DVR:v10.02.07.400-k-debug
----
. 驗證 `ql2xnvmeenable` 已設定、可讓Marvell介面卡以NVMe / FC啟動器的形式運作、使用下列命令：
+
[listing]
----
# cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----


--
====


=== 啟用 1MB I/O （選用）

ONTAP 會在識別控制器資料中報告 8 的 MDTS （ MAX Data 傳輸大小）。這表示最大 I/O 要求大小最多可達 1MB 。若要針對 Broadcom NVMe / FC 主機發出大小為 1 MB 的 I/O 要求，您應該將參數值 `lpfc_sg_seg_cnt`從預設值 64 增加 `lpfc`至 256 。


NOTE: 這些步驟不適用於 Qlogic NVMe / FC 主機。

.步驟
. 將 `lpfc_sg_seg_cnt`參數設定為 256 ：
+
[listing]
----
cat /etc/modprobe.d/lpfc.conf
----
+
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. 執行 `dracut -f`命令，然後重新啟動主機。
. 確認的值 `lpfc_sg_seg_cnt`為 256 ：
+
[listing]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----




== 設定NVMe/TCP

NVMe / TCP 沒有自動連線功能。因此、如果某個路徑發生故障、且在 10 分鐘的預設逾時期間內未恢復、則 NVMe / TCP 無法自動重新連線。若要避免逾時、您應該將容錯移轉事件的重試期間設為至少 30 分鐘。

.步驟
. 驗證啟動器連接埠是否可在支援的NVMe/TCP LIF中擷取探索記錄頁面資料：
+
[listing]
----
# nvme discover -t tcp -w 192.168.211.5 -a 192.168.211.14

Discovery Log Number of Records 8, Generation counter 10

=====Discovery Log Entry 0======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  0
trsvcid: 8009
subnqn:  nqn.199208.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:discovery
traddr:  192.168.211.15
sectype: none
=====Discovery Log Entry 1======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  1
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:discovery
traddr:  192.168.111.15
sectype: none
=====Discovery Log Entry 2======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  2
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:discovery
traddr:  192.168.211.14
sectype: none
=====Discovery Log Entry 3======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  3
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:discovery
traddr:  192.168.111.14
sectype: none
=====Discovery Log Entry 4======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:subsystem.rhel_tcp_165
traddr:  192.168.211.15
sectype: none
=====Discovery Log Entry 5======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  1
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:subsystem.rhel_tcp_165
traddr:  192.168.111.15
sectype: none
=====Discovery Log Entry 6======

trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  2
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:subsystem.rhel_tcp_165
traddr:  192.168.211.14
sectype: none

=====Discovery Log Entry 7======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified

   portid:  3

trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:subsystem.rhel_tcp_165
traddr:  192.168.111.14
sectype: none
[root@R650-13-79 ~]#
----
. 確認其他NVMe / TCP啟動器目標LIF組合可以成功擷取探索記錄頁面資料。例如：
+
[listing]
----
# nvme discover -t tcp -w 192.168.211.5 -a 192.168.211.14
# nvme discover -t tcp -w 192.168.211.5 -a 192.168.211.15
# nvme discover -t tcp -w 192.168.111.5 -a 192.168.111.14
# nvme discover -t tcp -w 192.168.111.5 -a 192.168.111.15

----
. 執行 `nvme connect-all` 跨節點執行所有支援的NVMe/TCP啟動器目標LIF命令。請確保設定更長的時間 `ctrl_loss_tmo` 定時器重試期間（例如30分鐘、可透過設定 `-l 1800`）在連線期間、以便在路徑遺失時、重試更長時間。例如：
+
[listing]
----
# nvme connect-all -t tcp -w 192.168.211.5-a 192.168.211.14 -l 1800
# nvme connect-all -t tcp -w 192.168.211.5 -a 192.168.211.15 -l 1800
# nvme connect-all -t tcp -w 192.168.111.5 -a 192.168.111.14 -l 1800
# nvme connect-all -t tcp -w 192.168.111.5 -a 192.168.111.15 -l 1800
----




== 驗證NVMe

您可以使用下列程序來驗證 NVMe 。

.步驟
. 檢查下列項目、確認內核NVMe多重路徑確實已啟用：
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y
----
. 驗證ONTAP 適當的NVMe設定值（例如、將「model」設為「NetApp還原控制器」、並將負載平衡「iopolicy」設為「循環」）、以正確ONTAP 反映在主機上：
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller

# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. 確認ONTAP 支援的名稱空間能正確反映在主機上。例如：
+
[listing]
----
# nvme list
Node           SN                    Model                   Namespace
------------   --------------------- ---------------------------------
/dev/nvme0n1   81Gx7NSiKSRNAAAAAAAB   NetApp ONTAP Controller   1

Usage                Format         FW Rev
-------------------  -----------    --------
21.47  GB /  21.47  GB  4 KiB + 0 B    FFFFFFFF
----
. 確認每個路徑的控制器狀態均為有效、且具有適當的ANA狀態。例如：
+
[listing, subs="+quotes"]
----
# nvme list-subsys /dev/nvme1n1

nvme-subsys0 - NQN=nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:subsystem.rhel_tcp_165

\

 +- nvme0 tcp traddr=192.168.211.15 trsvcid=4420 host_traddr=192.168.211.5 live non-optimized

 +- nvme1 tcp traddr=192.168.211.14 trsvcid=4420 host_traddr=192.168.211.5 live optimized

 +- nvme2 tcp traddr=192.168.111.15 trsvcid=4420 host_traddr=192.168.111.5 live non-optimized

 +- nvme3 tcp traddr=192.168.111.14 trsvcid=4420 host_traddr=192.168.111.5 live optimized
----
. 驗證NetApp外掛程式是否顯示每ONTAP 個支援的名稱空間設備的正確值。例如：
+
[listing]
----
# nvme netapp ontapdevices -o column
Device       Vserver          Namespace Path
---------    -------          --------------------------------------------------
/dev/nvme0n1 vs_tcp79     /vol/vol1/ns1 

NSID  UUID                                   Size
----  ------------------------------         ------
1     79c2c569-b7fa-42d5-b870-d9d6d7e5fa84  21.47GB


# nvme netapp ontapdevices -o json
{

  "ONTAPdevices" : [
  {

      "Device" : "/dev/nvme0n1",
      "Vserver" : "vs_tcp79",
      "Namespace_Path" : "/vol/vol1/ns1",
      "NSID" : 1,
      "UUID" : "79c2c569-b7fa-42d5-b870-d9d6d7e5fa84",
      "Size" : "21.47GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 5242880
    },

]

}
----




== 已知問題

採用 ONTAP 的 RHEL 8.7 NVMe 主機組態有下列已知問題：

[cols="20,40,40"]
|===
| NetApp錯誤ID | 標題 | 說明 


| link:https://mysupport.netapp.com/site/bugs-online/product/HOSTUTILITIES/BURT/1479047["1479047"^] | RHEL 8.7 NVMe主機會建立重複的持續探索控制器 | 在NVMe over Fabrics（NVMe）主機上、您可以使用「NVMe Discover-p」命令來建立持續探索控制器（PD）。使用此命令時、每個啟動器目標組合只能建立一個PDC。不過、如果您在ONTAP NVMe主機上執行的是Ris-9.10.1和Red Hat Enterprise Linux（RHEL）8.7、則每次執行「NVMe探索-p」時、都會建立一個重複的資料中心。這會導致主機和目標上的資源使用不必要。 
|===